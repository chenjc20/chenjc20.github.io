---
title: Exploiting Combined Locality for Wide-Stripe Erasure Coding in Distributed Storage
tags: 
  - tag: ML
  - tag: Sys4AI
  - tag: SSD
categories: FAST
author: 魏钧宇
---
本文提供了一种基于SSD的深度学习训练系统，它是用大容量但是低带宽的SSD来代替DRAM存储深度学习训练的中间结果，同时最大程度上降低了因为SSD低带宽低耐久所带来的问题。

本文的基本观察在于，随着NLP训练的模型规模的扩大，DRAM的容量逐渐不能够跟得上NLP模型的增长速度。为了解决这个问题通常的方法有：重算中间结果（引入额外的训练开销），采用模型并行同时流水线处理（不能够确保任务都能够有效划分）。本文观察到在整个训练的过程中，其实对于DRAM的带宽要求并不高，因为模型通常是计算密集型的，因此可以使用低带宽但是大容量的SSD来代替DRAM完成对于中间结果的缓存。

为了进一步降低传输的数据量，本文采用了一种称为WeightNode的策略，同时采用硬件的设计来提升SSD带宽，还引入了一些方案来解决SSD的耐久性的问题。

## 问题背景
本文通过背景分析希望表达如下的观点：即现有的自然语言处理模型需要更大的容量和相对较低的带宽。

首先先说容量这个层面，在现有的自然语言处理任务之中，模型的参数规模达到了350GB的规模，而与此同时在训练的过程中需要做Buffer每层的输出结果，这进一步加剧了计算过程中对于存储空间的需求（需要最多达2.1TB规模的空间）

另一方面，考虑带宽这个维度，因为在Transformer网络中，存在很多的FC层，需要较为密集的矩阵乘法计算，而且这里因为矩阵规模的庞大，这些计算通常是计算密集型的，所以对于存储的带宽需求其实是相对较低的。

## 整体流程
本文的主要策略就是将SSD作为深度学习训练任务的缓存，不仅缓存中间结果，而且还缓存模型参数。这是它和FlashNeuron的不同，后者是直接使用SSD来代替DRAM。在它的层次结构中，GPU的显存相当于SRAM，然后HostMememory相当于DRAM，SSD则相当于外存。

从整体来看，Behemoth将首先将做python的模型分析，同时生成一系列的指令。计算过程包括两类Node，一类是用于模型的更新，一类是用于计算Activation，不同的Activation执行数据并行，而WeightNode则作为一个类似于PS的结构，同步全局的参数。

![avatar](\assets\img\papers\2021-03-23\img1.png)

对于ActivationNode来说，主要的步骤包括从weightNode取权重，然后进行前向计算和后向更新，对应的流程如下图所示

![avatar](\assets\img\papers\2021-03-23\img2.png)

在前向传播的过程中，将首先从NAND Flash中权重读取到TensorBuffer之中，然后将这个权重分发给各个Activatio节点，这些节点将这个权重读取到GPU的显存之中，然后再使用GPU的计算部件完成计算，然后将计算得到的中间结果传回到TensorBuffer之中，再又TensorBuffer将结果存放到NAND之中。在后向传播的过程中，将首先从WeightNode中读出原始的权重，再将这个结果分发到各个ActivationNode之上，然后由这些Node从本地的SSD中读取权重，然后再在计算部件中更新具体数值，传回WeightNode进行下一步更新。
针对SSD所做的专门优化

## 针对SSD所做的优化

### 提升带宽
为了提升SSD写入的带宽，本文采用了一系列的相关方法，其核心思想在于充分利用DNN负载的特征，最小化各类SSD元数据管理所可能带来的开销。

首先，本文对于DNN训练过程中所可能存储到SSD上的那些数据做了分析。具体来说包括两大类：持久性的数据（例如训练数据，最终的模型）和临时数据（例如激活数值、中间权重等），对于持久性数据，普遍的操作是只读或者只有顺序写。对于临时的数据，也是只读一次，然后顺序写一次。本文将这两类数据在SSD上进行了分区存储。所以整体来看，只需要对于数据的顺序写性能做足够的优化即可，而不需要考虑随机写的特征可能会带来的影响。

其次，由于写永远是顺序的，本文去除FTL层中的负载均衡的特性，采用了最简单的循环物理块分配的策略，同时由于没有随机对于之前写的内容的修改，因此本文采用了一次性的整体性垃圾回收的方法，而不是采用FTL层所常见的分块细粒度的垃圾回收，另一方面本文对于临时数据，也不需要更新哪些用于确保其持久性的元数据。

采用上述的优化，本文能够保证SSD底层的硬件数据供给达到64GB/s，基本满足了上层的内存的数据要求。

### 提升耐久性
尽管直观来看，如果在SSD上存储临时数据，可能会造成SSD的耐久性下降。但是我们也需要考虑深度学习对于SSD存储特性的两个要求：第一，恰恰因为存储的是临时数据，所以对于SSD的持久性保存要求不高，即只需要保存几分钟即可，不需要保证很长时间的持久性存储。第二，因为所有的写都是顺序的，因此能够最大程度降低写放大和垃圾回收。

## 实验
本文的实验有两个部分，第一个是和基于TPU的这种平台比较内存开销，他是用模拟仿真的方法完成的，结果表明比TPU的内存节省了3.65x，第二个是和普通的SSD系统比带宽，这部分显示它的带宽要搞2.05x

## 心得
本文充分结合了深度学习的特性和SSD的内部特性，结合应用专门定制化地设计了系统，有一定启发性。
